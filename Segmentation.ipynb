{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Segmentation of Honeybees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is about segmentation of bee bodies based object detection method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "from functools import partial\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from segmentation import model,dataset, bee_dataset, training_config\n",
    "from segmentation.model import build_model\n",
    "from segmentation.results_analysis import find_positions, compute_error_metrics\n",
    "from segmentation.results_visualization import plot_positions, plot_segmentation_map, plot_TP_FN_FP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting the paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_dir = '/home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/dataset'\n",
    "num_classes = 3\n",
    "data_format = 'channels_last'\n",
    "bg_fg_weight = 0.9\n",
    "validation_num_files = 10\n",
    "batch_size= 8\n",
    "num_steps = 1000\n",
    "checkpoint_dir = '/home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to train our model. Here we are using the tensorlow estimator for that purpose. \n",
    "\n",
    "The Estimator object wraps a model which is specified by a model_fn, which, given inputs and a number of other parameters, returns the ops necessary to perform training, evaluation, or predictions.\n",
    "\n",
    "All outputs (checkpoints, event files, etc.) are written to model_dir, or a subdirectory thereof. If model_dir is not set, a temporary directory is used.\n",
    "\n",
    "The config argument can be passed tf.estimator.RunConfig object containing information about the execution environment. It is passed on to the model_fn, if the model_fn has a parameter named \"config\" (and input functions in the same manner). \n",
    "\n",
    "In the case of this project the model_fn used is that of the ever reliable Unet for segmentation. This has been handled in the helper python files \"unet.py\" and \"model.py\" present in the \"segmentation\" folder of the repository.  \n",
    "\n",
    "The dataset is prepared for training and evaluation and then the train_and_evaluate method is called. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:segmentation.training_config:Loading training config from /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/dataset/training_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f01483f4250>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f01483f4250>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.20386237, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.20386237, step = 0\n",
      "INFO:segmentation.bee_dataset:Skipping ._frame_30fps_001515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2021-02-16T15:04:22Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2021-02-16T15:04:22Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2021-02-16-15:04:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2021-02-16-15:04:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100: global_step = 100, loss = 0.149838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100: global_step = 100, loss = 0.149838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.22554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.22554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.15377139, step = 100 (31.004 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.15377139, step = 100 (31.004 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 200 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 200 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.88232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.88232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12150656, step = 200 (20.482 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12150656, step = 200 (20.482 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.76536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.76536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13061324, step = 300 (20.990 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13061324, step = 300 (20.990 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 400 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 400 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.27282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.27282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13507375, step = 400 (23.403 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13507375, step = 400 (23.403 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 500 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 500 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.38644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.38644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.101174265, step = 500 (22.793 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.101174265, step = 500 (22.793 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.4662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.4662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.10954331, step = 600 (22.391 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.10954331, step = 600 (22.391 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 700 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 700 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.44817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.44817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.113146245, step = 700 (22.483 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.113146245, step = 700 (22.483 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 800 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 800 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.28996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.28996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.09318423, step = 800 (23.309 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.09318423, step = 800 (23.309 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.24039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.24039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.08866664, step = 900 (23.589 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.08866664, step = 900 (23.589 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2021-02-16T15:08:14Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2021-02-16T15:08:14Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2021-02-16-15:08:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2021-02-16-15:08:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.08129069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.08129069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.09478972.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.09478972.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'loss': 0.08129069, 'global_step': 1000}, [])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_root_dir = os.path.join(dataset_root_dir, 'frames') # path to images\n",
    "labels_root_dir = os.path.join(dataset_root_dir, 'frames_txt') # path to labels\n",
    "\n",
    "if not (os.path.exists(images_root_dir) and os.path.exists(labels_root_dir)):\n",
    "    raise FileNotFoundError()\n",
    "\n",
    "config = training_config.get(dataset_root_dir)\n",
    "\n",
    "if config is None:\n",
    "    config = training_config.create(dataset_root_dir, validation_num_files)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=partial(build_model,\n",
    "                                                        num_classes=num_classes,\n",
    "                                                        data_format=data_format,\n",
    "                                                        bg_fg_weight=bg_fg_weight),\n",
    "                                       model_dir=checkpoint_dir,\n",
    "                                       config=tf.estimator.RunConfig(save_checkpoints_steps=100,\n",
    "                                                                     save_summary_steps=100))\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=partial(dataset.make_dataset,\n",
    "                                                         data_generator=partial(bee_dataset.generate_training,\n",
    "                                                                                frames_root_dir=images_root_dir,\n",
    "                                                                                labels_root_dir=labels_root_dir,\n",
    "                                                                                filenames=config['train']),\n",
    "                                                         data_format=data_format,\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         mode=tf.estimator.ModeKeys.TRAIN), max_steps=num_steps)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=partial(dataset.make_dataset,\n",
    "                                                       data_generator=partial(bee_dataset.generate_training,\n",
    "                                                                              frames_root_dir=images_root_dir,\n",
    "                                                                              labels_root_dir=labels_root_dir,\n",
    "                                                                              filenames=config['test']),\n",
    "                                                       data_format=data_format,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       mode=tf.estimator.ModeKeys.EVAL), steps=None)\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below a function is defined to create a text file and save the file with the position error, correct classes, True Positives, False Negatives and False Positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_error_file(point_d, axis_d, tps, fps, fns, correct_type, out_file):\n",
    "    total = len(point_d) + fns\n",
    "    tps_mn = float(tps) / total\n",
    "    fns_mn = float(fns) / total\n",
    "    fps_mn = float(fps) / total\n",
    "    correct_type_pr = float(correct_type) / tps\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        f.write(\"position error (pixels): mean: {:.2f} ({:.2f}) median: {:.2f}\\n\".format(np.mean(point_d),\n",
    "                                                                                         np.std(point_d),\n",
    "                                                                                         np.median(point_d)))\n",
    "        f.write(\"correct class: {:.2f}%\\n\".format(correct_type_pr * 100))\n",
    "        axis_d = np.rad2deg(axis_d)\n",
    "        f.write(\"axis error (degrees) : mean: {:.2f} ({:.2f}) median {:.2f}\\n\".format(np.mean(axis_d),\n",
    "                                                                                      np.std(axis_d),\n",
    "                                                                                      np.median(axis_d)))\n",
    "        f.write(\"True Positives: {:.2f}%\\n\".format(tps_mn * 100))\n",
    "        f.write(\"False Negatives: {:.2f}%\\n\".format(fns_mn * 100))\n",
    "        f.write(\"False Positives: {:.2f}%\\n\".format(fps_mn * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = '/home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/predict_result'\n",
    "min_distance_px = 20\n",
    "min_blob_size_px = 20\n",
    "max_blob_size_px = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(os.getcwd(), results_folder)\n",
    "if os.path.isdir(output_path):\n",
    "    shutil.rmtree(output_path)\n",
    "os.mkdir(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training_config.json file consists of the test- train split. With the helper functions in the \"training_config.py\" we can access the same and use it to load the training or test images and their corresponding labels as required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:segmentation.training_config:Loading training config from /home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/dataset/training_config.json\n"
     ]
    }
   ],
   "source": [
    "images_root_dir = os.path.join(dataset_root_dir, 'frames')\n",
    "labels_root_dir = os.path.join(dataset_root_dir, 'frames_txt')\n",
    "\n",
    "if not (os.path.exists(images_root_dir) and os.path.exists(labels_root_dir)):\n",
    "    raise FileNotFoundError()\n",
    "    \n",
    "config = training_config.get(dataset_root_dir)\n",
    "\n",
    "if config is not None:\n",
    "    to_predict_filenames = config['test']\n",
    "else:\n",
    "    to_predict_filenames = [os.path.splitext(x)[0] for x in os.listdir(images_root_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [bee_dataset.read_label_file_globalcoords(os.path.join(labels_root_dir, name + '.txt')) for name in to_predict_filenames]\n",
    "regions_of_interest = [l[1] for l in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model is then used to give the predictions on the test images that have been considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f01483f4a50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/kartik/Desktop/DeepLearningLecture_Schutera/Projects/segmentation/checkpoints', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f01483f4a50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn=partial(model.build_model,\n",
    "                                                        num_classes=num_classes,\n",
    "                                                        data_format=data_format,\n",
    "                                                        bg_fg_weight=None), model_dir=checkpoint_dir)\n",
    "\n",
    "predictions = estimator.predict(input_fn=partial(dataset.make_dataset,\n",
    "                                                     data_generator=partial(bee_dataset.generate_predict,\n",
    "                                                                            images_root_dir=images_root_dir,\n",
    "                                                                            filenames=to_predict_filenames,\n",
    "                                                                            regions_of_interest=regions_of_interest),\n",
    "                                                     data_format=data_format,\n",
    "                                                     batch_size=1,\n",
    "                                                     mode=tf.estimator.ModeKeys.PREDICT))\n",
    "\n",
    "drawing_functions = bee_dataset.get_object_drawing_functions()\n",
    "\n",
    "TP_count, FP_count, FN_count, correct_type_count = 0, 0, 0, 0\n",
    "all_pixel_dist, all_axis_diff = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each input frame, there will be 3 images generated - \n",
    "\n",
    "1. Segmentation map of bee bodies and abdomen\n",
    "2. Comparison of the predictions and label\n",
    "3. Diagram of the True Positives, False positives and False negatives\n",
    "\n",
    "A text file with the above information is also generated with the help of the save_error_file function defined earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, prediction, label in zip(to_predict_filenames, predictions, labels):\n",
    "\n",
    "    input_image = prediction['input_data']\n",
    "    pred_image = prediction['prediction']\n",
    "\n",
    "    channels_axis = 0 if data_format == 'channels_first' else -1\n",
    "    amax = np.argmax(pred_image, axis=channels_axis)\n",
    "\n",
    "    input_image = np.uint8(np.squeeze(input_image) * 255)\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    plot_segmentation_map(input_image, amax,\n",
    "                              os.path.join(output_path, \"{}_seg_map.png\".format(name)), num_classes=num_classes)\n",
    "\n",
    "    predictions_pos = find_positions(amax, min_blob_size_px, max_blob_size_px)\n",
    "    if len(predictions_pos) == 0:\n",
    "        continue\n",
    "\n",
    "    np.savetxt(os.path.join(output_path, \"{}_predictions.csv\".format(name)), predictions_pos, fmt=\"%i,%i,%i,%.4f\")\n",
    "    np.savetxt(os.path.join(output_path, \"{}_labels.csv\".format(name)), label[0], fmt=\"%i,%i,%i,%.4f\")\n",
    "\n",
    "    plot_positions(input_image, [label[0], predictions_pos], [(0, 250, 255), (0, 0, 255)],\n",
    "                    os.path.join(output_path, \"{}_mixed.png\".format(name)),\n",
    "                    drawing_params=drawing_functions)\n",
    "\n",
    "    pixel_dist, axis_diff, correct_type, TP_results, FN_results, FP_results \\\n",
    "        = compute_error_metrics(np.array(label[0]), np.array(predictions_pos), dist_min=min_distance_px)\n",
    "\n",
    "    TP_count += len(TP_results)\n",
    "    FN_count += len(FN_results)\n",
    "    FP_count += len(FP_results)\n",
    "    correct_type_count += correct_type\n",
    "    all_pixel_dist += pixel_dist\n",
    "    all_axis_diff += axis_diff\n",
    "\n",
    "    plot_TP_FN_FP(input_image, TP_results, FN_results, FP_results,\n",
    "                    os.path.join(output_path, \"{}_detail.png\".format(name)), drawing_functions)\n",
    "\n",
    "save_error_file(all_pixel_dist, all_axis_diff, TP_count, FP_count, FN_count, correct_type_count,\n",
    "                os.path.join(output_path, \"average_error_metrics.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
